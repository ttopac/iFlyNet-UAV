{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allState.shape: (238, 14, 599200)\n",
    "# liftdrag_arr.shape: (238, 2, 599200/333) = (238, 2, 1799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "main_dir = os.path.dirname(os.path.dirname(cur_dir))\n",
    "data_dir = os.path.join(main_dir, \"ConsolidatedData\", \"Training1_Jan2023\")\n",
    "\n",
    "all_df_dataname = \"videotimed_labeled_consolidated_all.pkl\"\n",
    "\n",
    "all_df_pkl = os.path.join(data_dir, all_df_dataname)\n",
    "\n",
    "with open(all_df_pkl, 'rb') as f:\n",
    "  all_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_datetimes = all_df[\"Date/Time\"].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d_%H-%M-%S-%f\"))\n",
    "\n",
    "unique_labels = all_df[\"Label\"].unique()\n",
    "unique_labels = np.delete(unique_labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_timing = dict()\n",
    "\n",
    "for label in unique_labels:\n",
    "  print (f\"Processing run: {label}\")\n",
    "\n",
    "  run_start_row_eds = all_df[all_df[\"Label\"] == label].index[0]\n",
    "  run_start_time = run_all_datetimes.iloc[run_start_row_eds]\n",
    "  run_row_cnt_eds = all_df[\"Label\"].value_counts()[label]\n",
    "  if run_start_row_eds + run_row_cnt_eds < run_all_datetimes.shape[0]:\n",
    "    run_end_time = run_all_datetimes.iloc[run_start_row_eds + run_row_cnt_eds]\n",
    "  else:\n",
    "    run_end_time = run_all_datetimes.iloc[-1]\n",
    "  \n",
    "  run_timing[label] = (run_start_time, run_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest = run_timing[unique_labels[0]][1] - run_timing[unique_labels[0]][0]\n",
    "for label,timing in run_timing.items():\n",
    "  duration = timing[1] - timing[0]\n",
    "  if duration < shortest:\n",
    "    shortest = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAQ_SAMPLERATE = 10000\n",
    "WINDOW_SIZE = 333\n",
    "liftdrag_arr = np.zeros((len(unique_labels), 2, int((shortest.seconds + shortest.microseconds/1000000) * DAQ_SAMPLERATE // WINDOW_SIZE)))\n",
    "\n",
    "timestep = datetime.timedelta(0,0,WINDOW_SIZE/DAQ_SAMPLERATE * 1000000) #Predicitons in every 333 SG/PZT samples. In time-scale, we need to make predictions in every 333/10000 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt,label in enumerate(unique_labels):\n",
    "  print (f\"Processing run {label}\")\n",
    "  \n",
    "  (run_start_time, run_end_time) = run_timing[label]\n",
    "  t = run_start_time\n",
    "  start_row_ix = run_all_datetimes[run_all_datetimes == t].index[0]\n",
    "  row_ix = start_row_ix\n",
    "  \n",
    "  sample_id = 0\n",
    "  while t < run_end_time:\n",
    "    while run_all_datetimes.iloc[row_ix] <= t+timestep:\n",
    "      row_ix += 1\n",
    "    \n",
    "    wt_lift = all_df[\"Lift (lbf)\"].iloc[start_row_ix:row_ix].mean()\n",
    "    wt_drag = all_df[\"Drag (lbf)\"].iloc[start_row_ix:row_ix].mean()\n",
    "\n",
    "    start_row_ix = row_ix\n",
    "    t += timestep\n",
    "\n",
    "    if sample_id + 1 <= liftdrag_arr.shape[2]:\n",
    "      liftdrag_arr[cnt, 0, sample_id] = wt_lift\n",
    "      liftdrag_arr[cnt, 1, sample_id] = wt_drag\n",
    "    \n",
    "    sample_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238, 2, 1799)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liftdrag_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join(main_dir, \"KerasML\", \"Training1_Jan2023\", \"data\")\n",
    "output_file = os.path.join(output_folder, \"sttr_aug2022_liftdraglabels.npy\")\n",
    "\n",
    "np.save(output_file,liftdrag_arr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
