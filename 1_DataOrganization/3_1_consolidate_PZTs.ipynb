{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "main_dir = os.path.dirname(os.path.dirname(cur_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = [\"08_02_2022\"]\n",
    "test_folders = [\"Day2_Training1_B_training\"]\n",
    "rtdstr_filenames = [\"training_rtdstr\"]\n",
    "pzt_filenames = [\"WTRUN2_day2_training1_B_2022-08-02_17-25-43-99_pzt_ch3F00FF00_0.05V\"]\n",
    "file_counts = [7]\n",
    "\n",
    "eds_rtdstr_offsets_dir = os.path.join(cur_dir, \"offset_pickles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verified that SG/RTD and PZT data exactly overlap at initiation. \n",
    "#So there's no need to offset a dataset from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frocessing PZT file: 1\n",
      "Frocessing PZT file: 2\n",
      "Frocessing PZT file: 3\n",
      "Frocessing PZT file: 4\n",
      "Frocessing PZT file: 5\n",
      "Frocessing PZT file: 6\n",
      "Frocessing PZT file: 7\n"
     ]
    }
   ],
   "source": [
    "#The block to load in and arrange the PZT data.\n",
    "pzt_combined_dfs = list()\n",
    "\n",
    "# Read in the offsets in IMGenie data. We'll use these values to crop out any extra lines lingering in PZT data.\n",
    "with open(os.path.join(eds_rtdstr_offsets_dir,'eds_rtdstr_offsets.pkl'), 'rb') as f:\n",
    "  eds_rtdstr_offsets = pickle.load(f)\n",
    "with open(os.path.join(eds_rtdstr_offsets_dir,'rtdstr_offsets_trailing.pkl'), 'rb') as f:\n",
    "  rtdstr_offsets_trailing = pickle.load(f)\n",
    "\n",
    "\n",
    "for i in range(len(test_folders)):\n",
    "  pzt_onetest_dfs = list()\n",
    "  data_dir = os.path.join(main_dir, test_dates[i]+\"_Tests\", \"testdata\", test_folders[i])\n",
    "  \n",
    "  #Read the RTDSTR file in case we'll need to do some realignment\n",
    "  rtdstr_filename = rtdstr_filenames[i]\n",
    "  rtdstr_file_csv = os.path.join(data_dir, rtdstr_filename)\n",
    "  rtdstr_file_df = pd.read_csv(rtdstr_file_csv+\".csv\", header=0)\n",
    "\n",
    "  #Insert proper time object\n",
    "  month = int (test_dates[i][0:2])\n",
    "  day = int (test_dates[i][3:5])\n",
    "  year = int (test_dates[i][6:])\n",
    "  rtdstr_times = rtdstr_file_df[\"Date/Time\"].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d_%H-%M-%S-%f\"))\n",
    "  rtdstr_times = rtdstr_times.apply(lambda x: datetime.datetime(year, month, day, x.hour, x.minute, x.second, x.microsecond)) #We do this because we haven't recorded date in the original data.\n",
    "  \n",
    "  if \"rtdstr_DateTime Obj\" not in rtdstr_file_df.columns:\n",
    "    rtdstr_file_df.insert(1, \"rtdstr_DateTime Obj\", rtdstr_times)\n",
    "  else:\n",
    "    rtdstr_file_df[\"rtdstr_DateTime Obj\"] = rtdstr_file_df[\"rtdstr_DateTime Obj\"].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "  for j in range(1,file_counts[i]+1):\n",
    "    print (f\"Frocessing PZT file: {j}\")\n",
    "    filename = pzt_filenames[i]+\"_\"+str(j)+\".csv\"\n",
    "    file_csv = os.path.join(data_dir, filename)\n",
    "    file_df = pd.read_csv(file_csv, header=0)\n",
    "    \n",
    "    if j == 1: #When its the start of the run\n",
    "      if eds_rtdstr_offsets[i][0] != \"rtdstr\": #if vantage[i] is not rtdstr (meaning that rtdstr started earlier, so some of it was cut).\n",
    "        #Determine how many seconds of IMGenie data we cut when aligning the data and crop out that many lines from PZT data.\n",
    "        seconds_passed = rtdstr_file_df[\"rtdstr_DateTime Obj\"][eds_rtdstr_offsets[i][1]] - rtdstr_file_df[\"rtdstr_DateTime Obj\"][0]\n",
    "        pzt_lines_passed = seconds_passed.seconds * 10000 + int(seconds_passed.microseconds * 0.01) #10000 PZT samples per second.\n",
    "        file_df = file_df.iloc[pzt_lines_passed:]\n",
    "    \n",
    "    if j == file_counts[i]: #When its the end of the run\n",
    "      #Determine how many seconds of IMGenie data we cut when aligning the data and crop out that many lines from PZT data.\n",
    "      seconds_passed = rtdstr_file_df[\"rtdstr_DateTime Obj\"].iloc[-1] - rtdstr_file_df[\"rtdstr_DateTime Obj\"].iloc[rtdstr_offsets_trailing[i]]\n",
    "      if seconds_passed != datetime.timedelta(0): #if vantage[i] is not rtdstr (meaning that rtdstr ended later, so some of it was cut).\n",
    "        pzt_lines_passed = seconds_passed.seconds * 10000 + int(seconds_passed.microseconds * 0.01) #10000 PZT samples per second.\n",
    "        file_df = file_df.iloc[:-1*pzt_lines_passed] \n",
    "    pzt_onetest_dfs.append(file_df)\n",
    "  pzt_combined_dfs.append(pzt_onetest_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat PZT dfs and save:\n",
    "df_save_dir = os.path.join(main_dir, \"ConsolidatedData\", \"Training1_B\")\n",
    "concated_pzt_dfs = list()\n",
    "\n",
    "for i, test_dfs in enumerate(pzt_combined_dfs):\n",
    "  concated_pzt_df = pd.concat((test_df for test_df in test_dfs), ignore_index=True)\n",
    "  concated_pzt_df.to_pickle(os.path.join(df_save_dir,f'consolidated_pzt_{i}.pkl'))\n",
    "  concated_pzt_dfs.append(concated_pzt_df)\n",
    "concated_all_pzt_df = pd.concat((concated_pzt_df for concated_pzt_df in concated_pzt_dfs), ignore_index=True)\n",
    "concated_all_pzt_df.to_pickle(os.path.join(df_save_dir,f'consolidated_pzt_all.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cae21afe383f91ea82811178060e59cc3e5895f013d1e4afce35f65192471b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
