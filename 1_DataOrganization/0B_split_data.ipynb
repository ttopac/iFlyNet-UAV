{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "main_dir = os.path.dirname(os.path.dirname(cur_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date = \"08_02_2022\"\n",
    "test_folder = \"Day2_Training1_B\"\n",
    "file_names = {\"eds\":\"DateTimed_WTRUN2_day2_training1_B_EDS\", \n",
    "              \"uav\":\"WTRUN2_day2_training1_B_UAV\",\n",
    "              \"rtdstr\":\"compensated_normalized_WTRUN2_day2_training1_B_2022-08-02_17-25-43-99_rtd-str\",\n",
    "              \"pzt\":\"WTRUN2_day2_training1_B_2022-08-02_17-25-43-99_pzt_ch3F00FF00_0.05V\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the EDS, UAV, and RTD-STR (IMGenie) data as Pandas Dataframes\n",
    "test_dfs = dict()\n",
    "data_dir = os.path.join(main_dir, test_date+\"_Tests\", \"testdata\", test_folder)\n",
    "\n",
    "for sensor_type in (\"eds\", \"uav\", \"rtdstr\"):\n",
    "  test_csv = os.path.join(data_dir, file_names[sensor_type]+\".csv\")\n",
    "  test_df = pd.read_csv(test_csv, header=0)\n",
    "  test_dfs[sensor_type] = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n"
     ]
    }
   ],
   "source": [
    "# First, add \"Label\" column to indicate flight condition where flag==0b10011 (capturing data) - ONLY FOR TRAINING DATA\n",
    "eds_df = test_dfs[\"eds\"]\n",
    "eds_df.insert(1, \"Label\", None)\n",
    "airspeeds = [7, 8.3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "aoas = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "conds = list()\n",
    "for airspeed in airspeeds:\n",
    "  for aoa in aoas:\n",
    "    conds.append (f\"{airspeed}m/s_{aoa}deg\")\n",
    "\n",
    "cond_ix = -1\n",
    "prev_flag = 0\n",
    "for row_ix in range(eds_df.shape[0]):\n",
    "  try: #Here try-except enforces labeling only for training part of the run.\n",
    "    if row_ix % 20000 == 0:\n",
    "      print (row_ix)\n",
    "    row = eds_df.iloc[row_ix]\n",
    "    if row[\"Flag\"] == \"0b10011\":\n",
    "      if prev_flag == 0:\n",
    "        cond_ix += 1\n",
    "        prev_flag = 1\n",
    "      eds_df.loc[row_ix, \"Label\"] = conds[cond_ix]\n",
    "    else:\n",
    "      prev_flag = 0\n",
    "  except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert DateTime objects to the dataframes.\n",
    "\n",
    "#Insert for EDS data:\n",
    "eds_times = test_dfs['eds'][\"DateTime Str\"].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "test_dfs['eds'].insert(1, \"eds_DateTime Obj\", eds_times)\n",
    "\n",
    "#Insert for RTD-STR data:\n",
    "month = int (test_date[0:2])\n",
    "day = int (test_date[3:5])\n",
    "year = int (test_date[6:])\n",
    "rtdstr_times = test_dfs['rtdstr'][\"Date/Time\"].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d_%H-%M-%S-%f\"))\n",
    "rtdstr_times = rtdstr_times.apply(lambda x: datetime.datetime(year, month, day, x.hour, x.minute, x.second, x.microsecond)) #We do this because we haven't recorded date in the original data.\n",
    "test_dfs['rtdstr'].insert(1, \"rtdstr_DateTime Obj\", rtdstr_times)\n",
    "\n",
    "#Insert for UAV data:\n",
    "#First define a function to separate full seconds into hours, minutes, seconds, and milliseconds\n",
    "def seperate_seconds(seconds):\n",
    "  #This function assumes inserted seconds is shorter than 24 hours = 86,400 seconds\n",
    "  onlyseconds = int(seconds.split(\".\")[0])\n",
    "  hours = int (onlyseconds/(60*60))\n",
    "  minutes = int (onlyseconds/(60)%60)\n",
    "  remseconds = int (onlyseconds - hours*60*60 - minutes*60)\n",
    "  milliseconds = seconds.split(\".\")[1][0:6]\n",
    "  return hours, minutes, remseconds, milliseconds\n",
    "\n",
    "seconds = test_dfs['uav'][\"STATIC_PRESSURE_TIME\"].astype(str)\n",
    "time_sr = seconds.apply(seperate_seconds)\n",
    "uav_times = time_sr.astype(str).apply(lambda x: datetime.datetime.strptime(x, \"(%H, %M, %S, '%f')\"))\n",
    "test_dfs['uav'].insert(1, \"uav_DateTime Obj\", uav_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust UAV's uav_DateTime Obj by first finding the 10 degree sync point on the UAV and EDS.\n",
    "# And correcting it using EDS's.\n",
    "observe_column_name = {\"eds\":\"Inclination (deg)\", \"uav\":\"Pitch (deg)\"}\n",
    "aoajump_ixs = dict()\n",
    "for data_stream in (\"uav\", \"eds\"):\n",
    "  #Find the indices of eds and uav streams where Inclination (deg) and Pitch (deg) increases by >4 degrees in 5 seconds.\n",
    "  \n",
    "  #Calculate the average time delta between each row.\n",
    "  time_delta = (test_dfs[data_stream][f\"{data_stream}_DateTime Obj\"][200] - test_dfs[data_stream][f\"{data_stream}_DateTime Obj\"][100])/100\n",
    "  \n",
    "  #Calculate diff for 5 seconds\n",
    "  num_rows = int(5/time_delta.total_seconds())\n",
    "  angle_change = test_dfs[data_stream][observe_column_name[data_stream]].diff(periods=num_rows)\n",
    "\n",
    "  #Extract the row ID where we see the first >4 degree change in 5 seconds (+10 degree calibration procedure).\n",
    "  aoajump_ix = angle_change[angle_change>4].index[0]\n",
    "  aoajump_ixs[data_stream] = aoajump_ix\n",
    "\n",
    "eds_aoajump_timestamp = test_dfs[\"eds\"][\"eds_DateTime Obj\"][aoajump_ixs[\"eds\"]]\n",
    "uav_aoajump_timestamp = test_dfs[\"uav\"][\"uav_DateTime Obj\"][aoajump_ixs[\"uav\"]]\n",
    "uav_timedelta = eds_aoajump_timestamp - uav_aoajump_timestamp\n",
    "\n",
    "test_dfs['uav'][\"uav_DateTime Obj\"] += uav_timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end_ix = eds_df.loc[eds_df[\"Label\"] == \"20m/s_16deg\"].iloc[-1].name\n",
    "training_end_time = eds_df.loc[training_end_ix][\"eds_DateTime Obj\"]\n",
    "training_end_time += datetime.timedelta(0,120,0) #Adding two minutes offset because we wait a resonable amount between training and dynamic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-08-02 20:28:56.681000')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the cutoff indices of data except for PZT\n",
    "cutoff_indices = dict()\n",
    "training_end_times = dict()\n",
    "for data_source in (\"uav\", \"rtdstr\", \"eds\"):\n",
    "  timedelta = datetime.timedelta(1)\n",
    "  ix = 0\n",
    "  while abs(training_end_time - test_dfs[data_source].iloc[ix][f\"{data_source}_DateTime Obj\"]) < timedelta:\n",
    "    timedelta = training_end_time - test_dfs[data_source].iloc[ix][f\"{data_source}_DateTime Obj\"]\n",
    "    ix += 10 #take big steps to step up the counter for speed as we don't have to be exact here.\n",
    "  cutoff_indices[data_source] = ix\n",
    "  training_end_times[data_source] = test_dfs[data_source].iloc[ix][f\"{data_source}_DateTime Obj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_indices['uav'] -= 500 #We move back UAV's cutoff index for consistency (we always assume UAV starts earlier than others)\n",
    "training_end_times['uav'] = test_dfs['uav'].iloc[cutoff_indices['uav']][\"uav_DateTime Obj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uav': 595430, 'rtdstr': 1419270, 'eds': 100430}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the split data into new csv files (except PZT)\n",
    "for data_source in (\"uav\", \"rtdstr\", \"eds\"):\n",
    "  for data_type in (\"training\", \"dynamic\"):\n",
    "    output_folder = os.path.join(main_dir, test_date+\"_Tests\", \"testdata\", test_folder+f\"_{data_type}\")\n",
    "    if data_type == \"training\":\n",
    "      output_csv = os.path.join(output_folder, f\"{data_type}_{data_source}.csv\")\n",
    "      test_dfs[data_source].loc[0:cutoff_indices[data_source]].to_csv(output_csv, index=False)\n",
    "    else:\n",
    "      output_csv = os.path.join(output_folder, f\"{data_type}_{data_source}.csv\")\n",
    "      test_dfs[data_source].loc[cutoff_indices[data_source]:].to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the cutoff index of PZT data\n",
    "start_time_rtdstr = test_dfs['eds'].iloc[0][\"eds_DateTime Obj\"]\n",
    "end_time_rtdstr = test_dfs['eds'].iloc[cutoff_indices['eds']][\"eds_DateTime Obj\"]\n",
    "\n",
    "time_elapsed_rtdstr = end_time_rtdstr - start_time_rtdstr\n",
    "minutes_elapsed_rtdstr = int (time_elapsed_rtdstr.total_seconds() // 60)\n",
    "pzt_csv_to_split = int(minutes_elapsed_rtdstr // 30) + 1 #Assuming PZT binaries are split per 30 minutes\n",
    "\n",
    "seconds_into = time_elapsed_rtdstr.total_seconds() - (pzt_csv_to_split-1)*30*60\n",
    "lines_into = seconds_into * 10000\n",
    "cutoff_indices['pzt'] = [str(pzt_csv_to_split), str(int(lines_into))] #(Suffix of PZT .csv file, index of cutoff line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uav': 595430, 'rtdstr': 1419270, 'eds': 100430, 'pzt': ['7', '1893950']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pzt_csv = os.path.join(data_dir, file_names['pzt']+\"_\"+cutoff_indices['pzt'][0]+\".csv\")\n",
    "pzt_df = pd.read_csv(pzt_csv, header=0)\n",
    "\n",
    "training_output_csv = os.path.join(main_dir, test_date+\"_Tests\", \"testdata\", test_folder+\"_training\", f\"training_pzt_{cutoff_indices['pzt'][0]}.csv\")\n",
    "pzt_df.loc[0:cutoff_indices['pzt'][1]].to_csv(training_output_csv, index=False)\n",
    "\n",
    "dynamic_output_csv = os.path.join(main_dir, test_date+\"_Tests\", \"testdata\", test_folder+\"_dynamic\", f\"dynamic_pzt_{cutoff_indices['pzt'][0]}.csv\")\n",
    "pzt_df.loc[cutoff_indices['pzt'][1]:].to_csv(dynamic_output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cae21afe383f91ea82811178060e59cc3e5895f013d1e4afce35f65192471b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
