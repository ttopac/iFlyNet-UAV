{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date = \"08_02_2022\"\n",
    "test_folder = \"Day2_Dynamic1\"\n",
    "test_name = \"WTRUN2_day2_dynamic1_EDS\"\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "main_dir = os.path.dirname(os.path.dirname(cur_dir))\n",
    "data_dir = os.path.join(main_dir, test_date+\"_Tests\", \"testdata\", test_folder)\n",
    "test_csv = os.path.join(data_dir, test_name+\".csv\")\n",
    "\n",
    "if \"EDS\" not in test_csv:\n",
    "  _ = input(\"The .csv file doesn't seem to belong to WT EDS stream. Are you sure you want to continue?\")\n",
    "\n",
    "eds_df = pd.read_csv(test_csv, header=0, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows when test point is changing:\n",
    "# We will use these rows to find out when Flag=1 during test\n",
    "# (the data we'll use for training)\n",
    "test_point_change = eds_df[\"Test Point\"].diff()\n",
    "test_pt_loc = eds_df.columns.get_loc(\"Test Point\")\n",
    "eds_df.insert(test_pt_loc+1, \"Test Point Change\", test_point_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp in df to a form that we can use for calculating time delta\n",
    "parsed_datetime_srs = eds_df[\"Parsed Date & Time\"].values.astype('str') # We're converting to a np.'str' array to be able to extract the millisecond component.\n",
    "\n",
    "def truncate_milliseconds(parsed_datetime_srs):\n",
    "  milliseconds = np.stack (np.char.split (np.stack(np.char.split(parsed_datetime_srs, \"seconds \"))[:,1], \" milliseconds\"))[:, 0] #Extracting \"millisecond\" field. Some conversions going on for compatibility.\n",
    "  pad = lambda x: x.zfill(3) #Actual truncation function\n",
    "  padded_arr = np.array(list(map(pad, milliseconds))) #Apply the function to all elements in the array.\n",
    "  return padded_arr\n",
    "\n",
    "milliseconds = truncate_milliseconds(parsed_datetime_srs) # truncating the 1- and 2-digit milliseconds to 3-digit for making them compatible with datetime.datetime.strptime function (bad design decision in the first place)\n",
    "lhs = np.stack(np.char.split(parsed_datetime_srs, \" seconds\"))[:,0]\n",
    "new_parsed_datetime = np.char.add(np.char.add(np.char.add(lhs,\" seconds \"), milliseconds), \" milliseconds\") #Concatenating fields. Similar to str+str, but stranger in np.char arrays.\n",
    "eds_df[\"Parsed Date & Time\"] = new_parsed_datetime\n",
    "\n",
    "eds_df.insert(1, \"DateTime Obj\", 0)\n",
    "eds_df[\"DateTime Obj\"] = eds_df[\"Parsed Date & Time\"].apply(lambda x: datetime.datetime.strptime(test_date+\" - \"+x, '%m_%d_%Y - %H hours %M minutes %S seconds %f milliseconds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_csv = os.path.join(data_dir, \"DateTimed_\"+test_name+\".csv\")\n",
    "eds_df.rename(columns={\"DateTime Obj\":\"DateTime Str\"}, inplace=True)\n",
    "eds_df.to_csv(output_test_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cae21afe383f91ea82811178060e59cc3e5895f013d1e4afce35f65192471b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
