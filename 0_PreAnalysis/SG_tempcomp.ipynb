{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from helpers.tempcomp_helper import get_comp_factors\n",
    "from helpers.tempcomp_helper import add_compensated_data_to_df\n",
    "from helpers.tempcomp_helper import add_compensated_data_to_df_infrequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date = \"08_02_2022\"\n",
    "test_folder = \"Day2_Dynamic1\"\n",
    "test_name = \"normalized_WTRUN2_day2_dynamic1_2022-08-02_14-32-54-11_rtd-str\"\n",
    "# test_date = \"08_01_2022\"\n",
    "# test_folder = \"Day1_Training1\"\n",
    "# test_name = \"normalized_WTRUN2_training_sweep1_2022-08-01_17-24-43-50_rtd-str\"\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "par_dir = os.path.abspath(os.path.join(cur_dir, os.pardir))\n",
    "up_dir = os.path.dirname(par_dir)\n",
    "data_dir = os.path.join(up_dir, test_date+\"_Tests\", \"testdata\", test_folder)\n",
    "test_csv = os.path.join(data_dir, test_name+\".csv\")\n",
    "\n",
    "if \"normalized\" not in test_csv:\n",
    "  _ = input(\"The .csv file is not normalized. Are you sure you'd like to continue?\")\n",
    "\n",
    "test_df = pd.read_csv(test_csv, header=1) #header=1 for normalized SGs/RTDs. header=0 for non-normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get Comp Factors\n",
    "The block below computes the compensation factors and exports them in .pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform filter applied to RTD 6.\n",
      "Uniform filter applied to RTD 6.\n"
     ]
    }
   ],
   "source": [
    "if \"heating_pretest\" not in test_name:\n",
    "  _ = input(\"\"\"You're trying to set compensation factors from a \n",
    "            different test than the controlled pre-heating test. \n",
    "            This is very likely not what you should do! Are you sure?\"\"\")\n",
    "\n",
    "sensor_id_list = [1, 2, 4, 5, 6]\n",
    "unique_rtds = False #Set whether we'd like to find compensation factors using unique RTDs or shared RTDs\n",
    "comp_factors = get_comp_factors(test_df, sensor_id_list, unique_rtds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not unique_rtds: #If we only have RTD 1 and RTD 6 available\n",
    "  data_name = \"compfactors_sharedRTDs.pickle\"\n",
    "else:\n",
    "  data_name = \"compfactors_uniqueRTDs.pickle\"\n",
    "\n",
    "with open(os.path.join(data_dir, data_name), 'wb') as f:\n",
    "  pickle.dump(comp_factors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Add Compensated Strains\n",
    "The block below computes the compensated data and creates a new .csv file with them in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform filter applied to RTD 6.\n"
     ]
    }
   ],
   "source": [
    "unique_rtds = True #Set whether we'd like to find compensation factors using unique RTDs or shared RTDs\n",
    "\n",
    "if unique_rtds == False: #If we only have RTD 1 and RTD 6 available\n",
    "  data_name = \"compfactors_sharedRTDs.pickle\"\n",
    "else:\n",
    "  data_name = \"compfactors_uniqueRTDs.pickle\"\n",
    "\n",
    "with open(os.path.join(data_dir, data_name), 'rb') as f:\n",
    "  comp_factors = pickle.load(f)\n",
    "\n",
    "test_df = add_compensated_data_to_df_infrequent (test_df, comp_factors)\n",
    "# test_df = add_compensated_data_to_df (test_df, comp_factors, unique_rtds)\n",
    "\n",
    "compensated_csv = os.path.join(data_dir, \"compensated_\"+test_name+\"_uniqueRTDs_infrequent.csv\")\n",
    "test_df.to_csv(compensated_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cae21afe383f91ea82811178060e59cc3e5895f013d1e4afce35f65192471b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
